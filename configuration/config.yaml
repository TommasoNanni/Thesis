data:
  data_root: "/cluster/project/cvg/data/EgoExo_georgiatech/raw/takes"
  output_directory: "/cluster/project/cvg/students/tnanni/ghost/test_outputs/segmentation_test_15"
  slice: 1                    # Number of scenes to load (set for testing)
  exclude_egocentric: true    # Exclude egocentric videos for simplicity
  smplx_model_path: "body_models"
  mhr_model_path: null

segmentation:
  sam2_checkpoint: "checkpoints/sam2.1_hiera_large.pt"
  sam2_cfg: "configs/sam2.1/sam2.1_hiera_l.yaml"
  gdino_id: "IDEA-Research/grounding-dino-tiny"
  box_threshold: 0.45         # minimum confidence for Grounding Dino to detect a bounding box
  text_threshold: 0.45        
  detection_step: 15          # Number of steps to propagate the prediction for

parameters_extraction:
  reid_threshold: 0.75
  gallery_moving_average_alpha: 0.9
  sam3d_id: "facebook/sam-3d-body-dinov3"
  sam3d_step: 1               # Predict using sam3d every sam3d_step frames
  bbox_padding: 0.2           # Padding added to the bounding box before cropping the image for SAM3D.    
